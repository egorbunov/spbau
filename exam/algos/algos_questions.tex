%!TEX program = xelatex

\input{env.tex}
\makeatletter
\def\input@path{{./figs/}}
\makeatother
\graphicspath{{./figs/}}

\title{Экзаменационные билеты \\ Алгоритмы. 5 курс. Весенний семестр.}
\author{Горбунов Егор Алексеевич}

\begin{document}
\maketitle

\section{Декартово дерево}
\begin{defn}
Декартово дерево -- это бинарное дерево, в каждой вершине которого хранится пара $(k, p)$, причём декартово дерево является деревом поиска по ключу $k$ и кучей по приоритету $p$.
\end{defn}

\begin{lem}
Пускай нам дан набор пар $(k_1, p_1), (k_2, p_2), \ldots, (k_n, p_n)$, причём все $p_i$ различны. Тогда существует единственное декартово дерево, построенное по этому набору пар.
\end{lem}
\begin{proof}
Будем рекурсивно (по индукции) строить декартово дерево. Все приоритеты $p_i$ различны, а значит среди пар можно выбрать \emph{единственную}, у которой приоритет $p_i = p_{max}$ максимальный. Относительно этого приоритета все пары мы можем однозначно разбить на две группы: в <<левую>> группу отправим пары у которых $p_i < p_{max}$, а в правую те, у которых $p_i \geq p_{max}$.
Таким образом разделили исходную задачу размера $n$ на более мелкие две. Построим соответственно декартово дерево на <<левой>> и <<правой>> группе и присоединим к корневой паре с приоритетом $p_{max}$. Дерево построено, значит существует. На каждом уровне выбор корня делается единственным способом (тут используем единственность приоритетов), а значит дерево единственно.
\end{proof}

\begin{note}
Алгоритм, описанный в доказательстве леммы отработает за $\bigO{n^2}$.
\end{note}

\subsection{Построение за линейное время}

Пускай нам дан \emph{уже отсортированный} по ключам в порядке возрастания набор пар $(k_1, p_1), \ldots, (k_n, p_n)$. 
Построим по ним декартово дерево быстро -- за $\bigO{n}$. Декартово дерево -- бинарное дерево поиска по ключам $k_i$, а это значит, что при добавлении ключей в порядке возрастания, добавляемая вершинка должна оказаться самой правой (у нас в левой веточке ключи $< k$, а в правой $\geq k$). Заметим таким образом, что мы всегда можем добавлять новую вершину $x$ в правую ветвь декартова дерева:

\begin{enumerate}[label=\arabic*.]
\item В самой правой ветви найти такие две вершины $a$ и $b$ ($b$ -- непосредственный сын $a$), что $a.p > x.p$ и $x.p > b.p$ (всякие граничные случаи где $a = NIL$ или $b = NIL$ не берём в голову, сейчас пофиг)
\item Перекинуть ссылки на сынишек: $x.l = b,\ a.r = x$
\end{enumerate}

\begin{figure}[ht!]
\centering
\begin{tikzpicture}[scale=1, baseline=(current bounding box.center)]
	\tikzstyle{every node}=[font=\scriptsize]
\begin{scope}[VertexStyle/.append style = {minimum size = 15pt}]
    \Vertex[NoLabel, Math, x=0, y=0]{root}
    \Vertex[Math, x=0.5, y=-1]{a}
    \Vertex[Math, x=1, y=-2]{b}
    \Vertex[NoLabel, Math, x=1.5, y=-3]{c}
\end{scope}
\begin{scope}[VertexStyle/.append style = {minimum size = 15pt, fill=blue!50}]
    \Vertex[Math, x=1.7, y=-1.25]{x}
\end{scope}
\begin{scope}[VertexStyle/.append style = {shape = regular polygon, regular polygon sides = 3}]
	\Vertex[NoLabel, Math, x=-0.5, y=-1]{X}
	\Vertex[NoLabel, Math, x=0, y=-2]{Y}
	\Vertex[NoLabel, Math, x=0.5,y=-3]{Z}
\end{scope}
\foreach \x/\y in {root/a, b/c} {\Edge[style=dashed](\x)(\y)}
\foreach \x/\y in {root/X, a/Y, b/Z} {\Edge(\x)(\y)}
\tikzset{LabelStyle/.style= {fill=none}}
\Edge[label=\tiny{$a.r$}, color=blue!50](a)(x)
\Edge[label=\tiny{$x.l$}, color=blue!50](x)(b)
\tikzset{LabelStyle/.style= {fill=none, text=red}}
\Edge[label=\Large{$\times$}](a)(b)
\end{tikzpicture}
\caption{Вставка вершины $x$ при построении декартова дерева}
\end{figure}

Как находить такие вершины $a$ и $b$? Можно спускаться от корня вниз и вправо. Но тогда представим себе такую ситуацию: на вход подали набор пар $(1, 1), (2, 2), (3, 3), \ldots, (n, n)$. Пары отсортированы как надо. На каждой итерации алгоритма построения дерева новая вершина будет добавляться в самый конец пути вправо, таким образом для нахождения вершины $a$ мы каждый раз будем спускаться вниз проходя по $i$ вершин на $i$-ой итерации. Это как-то квадратично, а мы хотим за $\bigO{n}$.

Будем искать место для вставки с конца правой ветки. Почему это разумно? А потому, что веточка снизу ломается влево каждый раз при добавлении новой вершины там, куда её добавили. Это наводит на разные амортизационные мысли. Имеем дерево $T$, которое строится.
\[
	\Phi_i(T) = \text{длина правой ветки дерева перед $i$-ой итерацией}
\]
Тогда амортизационная стоимость итерации (добавления одной вершинки) равна (тут $t$ --- это то, сколько мы прошли по правой ветки снизу в поисках места вставки)
\[
	\tilde{c_i} = t + \Delta_i \Phi = t + ((l - t + 1) - l) = t - t + 1 = 1 = \bigO{1}
\]
Таким образом амортизационная оценка на построение всего дерева: $\bigO{n}$!
\subsection{Операции вставки и удаления}
Для вставки и удаления введём 2 дополнительные операции: \texttt{Split} и \texttt{Merge}

\begin{itemize}
\item \emph{Процедура \texttt{Split}} принимает на вход дерево $T$ и ключик $k$, а возвращает 2 декартовых дерева: в первом дереве все ключики $< k$, а во втором $\geq k$.
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def Split(T, k):
    if T == nil: return (nil, nil) # nil is empty tree or something like this...
    if T.k < k:
        (T.r, R) = Split(T.r, k)
        return (T, R)
    else:
        (L, T.l) = Split(T.l, k)
        return (L, T)
\end{minted}
Логика проста: если ключ в корне дерева меньше $k$, то этот корень уже находится в искомой <<левой>> половине разбиения (сплита, разреза, как хотите!), а значит <<правую>> половину разбиения мы берём из рекурсивного разбиения правого сына, а левые остатки присоединяем к итоговой левой части.

\item \emph{Процедура \texttt{Merge}} принимает на вход два дерева $L$ и $R$, причём таких, что ключи в первом дереве меньше либо равны ключам во втором и возвращает декартово дерево содержащее ключи обоих деревьев. Опять просто и рекурсивно:
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def Merge(L, R):
	if size(L) == 0: return R
	if size(R) == 0: return L
	if L.p > R.p:
	    L.r = Merge(L.r, R)
	    return L
	else:
	    R.l = Merge(L, R.l)
	    return R
\end{minted}
Тут мы просто уменьшаем задачу валидным способом...

\item \emph{Вставка в дерево}: процедура \texttt{Insert}. Процедура будет принимать дерево и новую вершину, а возвращать изменённое дерево.
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def Insert(T, node)
	L, R = Split(T, node.k)
	return Merge(Merge(L, node), R)
\end{minted}
Заметим, что мы используем тут целых 2 слияния и 1 сплит. Можно чуть лучше. Если у \texttt{node} приоритет выше, чем у \texttt{T}, то достаточно посплитить \texttt{T}, а потом присоединить результат к \texttt{node}. Если же приоритет меньше, то мы можем спуститься по \texttt{T} как по дереву поиска до той вершины, где её приоритет будет выше.
\begin{minted}[linenos, fontsize=\footnotesize]{python}
def Insert(T, node):
    if node.p > T.p:
        node.l, node.r = Split(T, node.k)
        return node
    if node.k < T.k:
        T.l = Insert(T.l, node) 
    else:
        T.r = Insert(T.r, node)
    return T # root of result tree is T
\end{minted}

\item \emph{Удаление из дерева}: процедура \texttt{Remove}. Принимаем дерево и ключ, а возвращаем дерево, их которого вершинка с ключиком была удалена.
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def Remove(T, k)
	L, R = Split(T, k)
	D, R = Split(R, k)
	return Merge(L, R)
\end{minted}
Тут делается 2 сплита и 1 слияние, но можно лучше. Ясно, что если \texttt{T.k == k}, то нам просто нужно вернуть слитых левого и правого сына \texttt{T}. Этим и воспользуемся:
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def Remove(T, k)
    if T.k == k:
        return Merge(T.l, T.r)
    if k < T.k:
        T.l = Remove(T.l, k)
    else:
        T.r = Remove(T.r, k)
    return T
\end{minted}

\end{itemize}

\begin{note} 
Легко видеть, что время работы операций \texttt{Split} и \texttt{Merge} --- $\bigO{h}$, где $h$ --- высота дерева. А значит аналогично и время работы вставки и удаления.
\end{note}

\subsection{Дуча (Treap, Дерамида)}

\begin{defn}
Дуча --- это декартово дерево, приоритеты в котором случайные и равномерно распределённые.
\end{defn}
\begin{lem}
Математическое ожидание высоты дучи равно $\bigO{\log{n}}$, где $n$ --- число вершин в ней.
\end{lem}
\begin{proof}
Обратимся к рекурсивному (тот, что за $\bigO{n^2}$) алгоритму построения декартова дерева. Заметим, что в силу случайности приоритетов мы равновероятно выбираем любой ключ при построении дерева, относительно которого все остальные ключи будут разбиты по группам $<$ или $\geq$. Это в точности та же процедура, которая происходит при применении быстрой сортировки. И дерево рекурсии для этих задач идентичны. Умеем доказывать, что дерево рекурсии \texttt{QuickSort} будет иметь высоту, в среднем (из-за случайности процесса, а не по входам), логарифмическую! 
\end{proof}
Выводы: таким образом \texttt{Treap} -- это дерево поиска, операции на котором будут работать за $\bigO{\log{n}}$.

\section{Задачи \texttt{RMQ} и \texttt{LCA}}

\begin{defn}
Дан массив $A$. Задача \texttt{\textbf{RMQ}} или \texttt{Range Minimum Query} заключается в том, что по запросу $[l, r]$, $l \leq r$, $l, r \in \mathbb{N}$ нужно найти $\min_{i \in [l, r]}{A[i]}$.
\end{defn}
\begin{defn}
Пусть дано дерево $T$. Задача \texttt{\textbf{LCA}} или \texttt{Least Common Ancestor} заключается в том, что по запросу $(v, u)$, где $v$ и $u$ есть вершины дерева $T$, нужно найти вершину $p \in T$ такую, что $p$ --- общий предок $v$ и $u$ и при этом он самый близкий к ним, т.е. нету вершины $p'$, которая общий предок $v$ и $u$ и при этом её глубина больше глубины $p$.  
\end{defn}
Задачи \texttt{RMQ} и \texttt{LCA} можно решать в разных условиях: когда исходный массив или дерево могут меняться (динамическая задача) или когда они даны и неизменны (статическая задача).
\begin{note}
Заранее скажем, что существует круговорот \texttt{RMQ} и \texttt{LCA} в природе, а именно: \texttt{RMQ} сводится к \texttt{LCA}, а \texttt{LCA} сводится к \texttt{RMQ$\pm 1$}, что есть частный случай задачи \texttt{RMQ}.
\end{note}
\begin{note}
В лоб задачи \texttt{LCA} и \texttt{RMQ} решаются за $\bigO{n}$ (ответ на один запрос, на дерево никаких ограничений в духе сбалансированности нет). Но мы научимся (возможно, описано тут некоторое не будет) решать быстрее:
\begin{table}[ht!]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
            & Дерево отрезков & Полный предподсчёт & Sparse Table \\
\hline
предподсчёт & $\bigO{n}$        & $\bigO{n^2}$         & $\bigO{n\log{n}}$ \\
\hline
запрос      & $\bigO{\log{n}}$  & $\bigO{1}$ & $\bigO{1}$ \\
\hline
динамически?  & \color{OliveGreen}{да} & \color{red}{нет} & \color{red}{нет} \\
\hline
\end{tabular}
\caption{Задача \texttt{RMQ}}
\end{table}

\begin{table}[ht!]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
            & Двоичные подъёмы & Полный предподсчёт & \texttt{Ladder decomposition} \\
\hline
предподсчёт & $\bigO{n\log{n}}$        & $\bigO{n^2}$ &  $\bigO{n\log{n}}$ \\
\hline
запрос      & $\bigO{\log{n}}$  & $\bigO{1}$ & $\bigO{1}$\\
\hline
динамически?  & \color{red}{нет} & \color{red}{нет} & \color{red}{нет}\\
\hline
\end{tabular}
\caption{Задача \texttt{LCA}, если решать именно как \texttt{LCA} :) Под \texttt{Ladder Decomposition} понимается разложения дерева на <<длиннейшие>> пути, а потом наворачивание поверх этого двоичных подъёмов (самый обычных), в этом документе про это точно не будет. }
\end{table}
Так же мы научимся сводить \texttt{RMQ} к \texttt{LCA} и наоборот за линейное $\bigO{n}$ время, так что методы решения одной задачи можно использовать для решения другой.
\end{note}
\subsection{Динамический \texttt{RMQ} и \texttt{RSQ}. Дерево отрезков}
Пускай у нас есть ассоциативная операция $\circ$, например $\min$ или $+$. Заметим тогда, что при вычислении $A[l] \circ A[l+1] \circ A[l+2] \circ \ldots \circ A[r]$ мы можем в силу ассоциативности расставлять скобки как хотим. Построим такую структуру данных, которая нам будет разбивать отрезок запроса на некоторое число \emph{непересекающихся} подотрезков, на которых ответ уже посчитан. Тогда, в силу ассоциативности, мы можем получить ответ на всё отрезке. Далее в качестве операции будем рассматривать, например, $+$.
\begin{defn}
\emph{Дерево отрезков} --- это такое бинарное дерево, что его корень ассоциирован со всем массивом $A[1..n]$, а дети вершины, которой соответствует кусок массива $A[l..r]$, ассоциированы с кусками массива $A[l..m]$ и $A[m+1..r]$, где $m = \frac{l + r}{2}$. См. рисунок~\ref{fig:segtree}
\end{defn}
В каждой вершине такого дерева мы можем хранить ответ на запрос на отрезке, которому эта вершина соответствует.

\subsubsection{Построение дерева отрезков}
Построить дерево можно за линию. Считаем, что длина исходного массива $n = 2^k$. Всего вершин в дереве $2n$, т.к. это полное бинарное дерево на $n$ листьях (можешь доказать это через лемму о рукопожатиях, например). Само дерево можно хранить в массиве \texttt{tree[2*n]} так, что \texttt{tree[1]} --- это корень дерева отрезков, который соответствует всему массиву. А дети \texttt{i}-ой вершины --- это вершины \texttt{tree[2*i]} и \texttt{tree[2*i+1]}. Т.е. отец вершины \texttt{tree[j]} --- это \texttt{tree[j / 2]}.
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def build(arr):
    tree = [0] * (2 * len(arr) + 1)
    tree[len(arr) + 1:] = list(arr)
    for i in reversed(range(1, len(arr)+1)):
        tree[i] = tree[2 * i] + tree[2 * i + 1]
    return tree
\end{minted}
Ясно, что строим за $\bigO{n}$.
\begin{figure}[ht!]
\centering
\input{segment_tree.pdf_tex}
\caption{Дерево отрезков для данного массива $A$. Если размер $A$ не степень двойки, то добьём до степени двойки нейтральными элементами относительно той операции, которую хотим считать на отрезках массива.}
\label{fig:segtree}
\end{figure}

\subsection{Ответ на запрос и оценка на время работы}
Отвечать на запрос о сумме (минимуме, ...) на отрезке будем декомпозируя искомый отрезок на куски, которые представляют из себя вершины дерева отрезков.
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def sum(v, l, r, ql, qr):
    """
    v - индекс вершины дерева отрезков в массиве tree
    l, r - границы отрезка, за которые вершина v отвечает
    ql, qr - текущие границы запроса, ql >= l и qr <= r
    """
    if ql > qr:
        return 0
    if l == ql and r == qr:
        return tree[v]
    m = (l + r) / 2
    return sum(2*v, l, m, ql, min(m, qr)) + sum(2*v+1, m+1, r, max(m+1, ql), qr)
\end{minted}
Нужно понять, как быстро это работает?
\begin{lem}
Вызов \mintinline{python}{sum(1, 0, n-1, l, r)} отрабатывает за $\bigO{\log{n}}$.
\end{lem} 
\begin{proof}
Заметим следующую вещь. Всего может быть 2 случая:
\begin{enumerate}[label=\arabic*.]
\item Если какая-то граница отрезка \texttt{[l, r]} совпала с какой-то границой отрезка \texttt{[0, n-1]}.
\begin{figure}[ht!]
\centering
\def\svgwidth{0.4\columnwidth} 
\input{rec_seg_1.pdf_tex}
\caption{Хотя бы одна из границ совпала.}
\label{fig:rec_seg_1}
\end{figure}
Видим тогда, что у нас один из ветвей рекурсии сразу же остановится и останется ещё всего лишь одна. Т.е. можно считать, что число ветвей рекурсии не увеличивается.
\item \label{segfast:case:1} Если у нас ни одна из границ не совпала и при этом отрезок \texttt{[l,r]} не пересекает середину отрезка, соответствующего вершине, то тогда у нас опять же число ветвей рекурсии на этом шаге не увеличивается.
\item Если же ни одна из границ не совпала, а отрезок \texttt{[l,r]} пересекает середину, то ситуация получается такой:
\begin{figure}[ht!]
\centering
\def\svgwidth{0.4\columnwidth} 
\input{rec_seg_2.pdf_tex}
\caption{Отрезок \texttt{[l, r]} пересекает середину отрезка вершины}
\label{fig:rec_seg_2}
\end{figure}
Видим тогда, что у нас увеличилось число ветвей рекурсии. Их стало две. Но заметим тогда, что обе эти ветви рекурсии удовлетворяют случаю~\ref{segfast:case:1}. А значит, что ни одна из порождённых ветвей рекурсии не расплодится (больше чем на один шаг).
\end{enumerate}
Получили таким образом, что максимальное число ветвей рекурсии равно $4$ (это видно на рисунке~\ref{fig:rec_seg_2}), но это значит, что время работы ответа на запрос пропорционально высоте дерева отрезков, а высота этого дерева, очевидно, $\log{n}$. Вот и получили $\bigO{\log{n}}$ на запрос.
\end{proof}
\begin{note}
Из леммы так же следует, что мы можем любой отрезок разбить на $\bigO{\log{n}}$ отрезков из дерева (канонических отрезков). Иначе мы бы не могли получить такой асимптотики.
\end{note}
\subsubsection{Обновление элемента массива}
Тут всё просто. Каждый элемент массива покрывается ровно $\log{n}$ каноническими отрезками. Это, к слову, хорошо видно из рисунка~\ref{fig:segtree}. Таким образом нам нужно просто обновить значение на всех этих отрезках. Это делается либо проходом сверху вниз, либо снизу вверх (тут нам помогает наш способ хранения дерева через массив и удобная адресация к родителю вершины).
\begin{minted}[mathescape, linenos, fontsize=\footnotesize]{python}
def update(v, l, r, idx, val):
    if l == r and l == idx:
        tree[l] = val
    else:
        m = (l + r) / 2
        if idx <= m:
            update(2*v, l, m, idx, val)
        else:
            update(2*v+1, m+1, r, idx, val)
        tree[v] = tree[2*v] + tree[2*v+1] # or min(tree[2*v], tree[2*v+1])
\end{minted}
Тут совсем ясно, что мы тратим ровно высоту времени, т.е. $\bigO{\log{n}}$
\begin{note}
Быстрее делать обе операции (запрос и изменение) нельзя. Если бы было можно, то и массив бы мы отсортировали быстрее, чем за $\bigO{n\log{n}}$ (достаём минимум, заменяем элемент по его индексу на $\infty$), а это теоретически невозможно.
\end{note}

\subsection{Статический \texttt{RMQ}. Sparse table}
Пускай у нас теперь исходный массив фиксирован и не меняется. Нужно лишь уметь отвечать на запросы минимум на отрезке \texttt{[l, r]}.
\begin{enumerate}[label=\arabic*.]
\item Полный предподсчёт. Можно просто взять и для всех пар подсчитать ответ за $\bigO{n^2}$, после чего отвечать на каждый запрос за $\bigO{1}$. 
\item \texttt{\textbf{Sparse Table}} или Разреженная таблица. В данной ситуации нам важно, что операция, которую мы хотим считать на массиве, \emph{идемпотентна}. Заметим такую вещь: если исходный запрос $[l, r]$ мы разобъём на 2 \emph{пересекающихся} подотрезка $[l, l + 2^k]$ и $[r - 2^k, r]$, то $\min_{[l, r]} = \min(\min_{[l, l + 2^k]}, \min_{[r - 2^k, r]})$. Тут $2^k$ максимальное такое, что $r - l + 1 \geq 2^k$. Суть в том, что такие 2 отрезка гарантированно покроют весь отрезок $[l, r]$. Суть метода \texttt{Sparse Table} в том, что мы предподсчитываем ответы на запросы на всех отрезках, длина которых --- степень двойки. Вплоть до длины $\log{n}$. Таким образом предподсчёт у нас займёт $\bigO{n\log{n}}$. Идемпотентность нам нужна, т.к. отрезки, на которые мы разбиваем запрос, могут пересекаться.
\item Для операций, у которых есть обратная операция, мы можем предподсчитать за $\bigO{n}$ результаты на префиксах массива, а потом отвечать за $\bigO{1}$.
\end{enumerate}

\subsection{\texttt{LCA}. Эйлеровы обходы. Сведение к \texttt{RMQ} и наоборот}
\subsubsection{Сведение \texttt{RMQ} к \texttt{LCA}}
Пусть у нас есть массив $A[1..n]$. Рассмотрим набор пар $(A[i], i)$ и построим по нему декартово дерево, где $i$ (индексы в массиве) будут ключами, а приоритетами будут $A[i]$. Ясно, что т.к. полученное дерево будет деревом поиска по индексам и кучей по элементам массива, то наибольший общий предок вершины $(A[l], l)$ и вершины $(A[r], r)$ --- это такая вершина $(A[i], i)$, что $l \leq i \leq r$ и $A[i] \leq A[l], A[r]$. Это ясно по построению и свойствам дерева.

\subsubsection{Эйлеров обход}
Эйлеровы обходы бывают разные. Пускай у нас есть дерево:
\begin{figure}[ht!]
\centering
\begin{tikzpicture}[scale=1, baseline=(current bounding box.center)]
	\tikzstyle{every node}=[font=\scriptsize]
\begin{scope}[VertexStyle/.append style = {minimum size = 15pt}]
    \Vertex[Math, x=0, y=0]{1}
    \Vertex[Math, x=0.5, y=-1]{3}
    \Vertex[Math, x=0, y=-2]{5}
    \Vertex[Math, x=-1, y=-2]{4}
    \Vertex[Math, x=-0.5, y=-1]{2}
\end{scope}
\foreach \x/\y in {1/2, 1/3, 2/4, 2/5} {\Edge(\x)(\y)}
\end{tikzpicture}
\end{figure}
Эйлеров обход --- это своеобразный протокол обхода в глубину данного дерева.
Эйлеровы обходы бывают следующие:
\begin{enumerate}
	\item \emph{Обход по рёбрам}. Обходим дерево начиная с корня по рёбрам слева направо. Проходя по ребру добавляем его к обходу.
	\[ (1,2),\ (2,4),\ (4,2),\ (2,5),\ (5,2),\ (2,1),\ (1,3),\, (3,1) \]
	\item \emph{Обход по вершинам с повторениями.}
	\[ 1, 2, 4, 2, 5, 2, 1, 3, 1 \]
	\item \emph{Обход по вершинам}, где вершина добавляется в обход при входе в её поддерево и при выходе.
	\[ 1, 2, 4, 4, 5, 5, 2, 3, 3, 1\]
\end{enumerate}
Будем эйлеровым обходом называть обход по вершинам с повторениями. Заметим следующую вещь. Пронумеруем все вершины в порядке обхода \emph{в ширину}, т.е. чтобы у вершины с меньшей глубиной всегда был больший номер. Теперь пусть мы хотим найти \texttt{LCA} вершин $a$ и $b$. Тогда посмотрим на индекс $i$ первого вхождения $a$ в эйлеровом обходе и индекс $r$ первого вхождения $j$ в эйлеровом обходе. Не умаляя общности пускай $i < j$. Что может находится между позициями $i$ и $j$ в эйлеровом обходе? В силу устройства эйлерова обхода, если $b$ не находится в поддереве $a$, то между $i$ и $j$ может лежать единственный общий предок $a$ и $b$ и причём он будет наименьшим (\texttt{least common ancestor}) и он будет иметь наименьший номер. Если же $b$ лежит в поддереве $a$, то $a$ и будет ответом на запрос. Заметим, что в силу нумерации получается, что для ответа на запрос нам нужно найти минимум на отрезке $[i, j]$ в эйлеровом обходе. Таким образом будем хранить массив $first[1..n]$ первых вхождений каждой вершины. Если потребуется найти $lca(a,b)$, то нужно спрашивать $rmq(first[a], first[b])$. Свели.
\begin{note}
Какова длина эйлерова обхода? Если смотреть на то, как мы ходим по рёбрам, то можно заметить, что в обход мы добавляем конец каждого ребра (когда идём вних) и начало каждого ребра (когда поднимаемся наверх), плюс ещё корень, который появляется вначале, потому что с него начинаем (очевидно). Итого $2(n-1)+1 = 2n-1$. А значит сведение работает за $\bigO{n}$.
\end{note}
\begin{note}
Существует алгоритм решения \texttt{RMQ$\pm 1$} за $\bigO{n}$ предподсчёт и $\bigO{1}$ на запрос. А т.к. мы всё ко всему умеем сводить, то для $LCA$ и $RMQ$ в общем случае тоже можно получить такую асимптотику.
\end{note}

\section{Хеширование 1}
\subsection{Прямая адресация. Хеширование. Коллизии}
\subsection{Методы разрешения коллизий}
\subsection{Гипотеза равномерного хеширования}
\subsection{Оценка времени поиска в хеш-таблице}

\end{document}
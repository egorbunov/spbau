{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вопросы к экзамену"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг. Масштабирование. Нормировка. Бинаризация. Полиномиальные признаки. One-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков произодится в силу того, что некоторые ML-методы плохо работают, когда у признаков сильно разнятся области значений (например, когда приходится считать расстояние между точками выборки, то без мастабирования, на результат может сильно влиять один признак, а другие почти не учитываться).\n",
    "\n",
    "**Масштабирование** (Rescaling) - это приведение области значений признака $x$ к $[0, 1]$ или $[-1, 1]$ (википедия):\n",
    "$$\n",
    "    x' = \\frac{x - min(x)}{max(x) - min(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нормировка** (Standardization) - это приведение выборки фич к значениям с *нулевым* матожиданием и *единичным* стандартным отклонением (nb, дисперсия = квадрат std):\n",
    "$$\n",
    "    x' = \\frac{x - \\overline{x}}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда имеет смысл усложнить исходный набор признаков $(X_1, X_2)$ *полиномиальным признаками*: $(1, X_1, X_2, X_1^2, X_1X_2, X_2^2)$. Это имеет смысл, например, при использовании линейных методов (линейной регрессии всякой), которые не могут нам показать больше, чем линейных зависимостей по данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Бинаризация признаков** - приведение числовых признаков к бинарным $\\{0, 1\\}$. Это бывает нужно при решении задач классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**. Из названия можно (со скрипом) догадаться, что речь идёт о кодировании чего-то вектором из нулей, но с одной единичкой. Например, есть у нас категориальный признак $\\{ A, B, C, D \\}$. Тогда мы можем его распилить на $4$ признака соответственно $A$, $B$, $C$, $D$, причём каждый из этих признаков может быть, например, вещественным из $[0, 1]$. А объекту из обучающей выборки, у которого категория, например, $A$, мы ставим в соответствие 4 фичи $1, 0, 0, 0$. Далее можно такие признаки пихать в обучатель и работать с ними как с обычными числовыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация. kMeans, MeanShift, Affinity Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача кластеризации** - задача разбиения заданной выборки объектов (ситуаций) на непересекающиеся подмножества, называемые кластерами, так, чтобы *каждый кластер состоял из схожих объектов*, а *объекты разных кластеров существенно отличались*.\n",
    "Задача кластеризации относится к широкому классу задач *обучения без учителя*. ( [источник](http://www.machinelearning.ru/wiki/index.php?title=%D0%9A%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F) )\n",
    "\n",
    "Цели: выявить закономерности, найти необычные объекты, дальнейшее применение разных моделей и прочего к разным кластерам, построение иерархии классов объектов, уменьшить объём данных (брать по объекту из кластера)\n",
    "\n",
    "Проблемы: вопрос выбора числа кластеров, вопрос выбора метрики расстояния, вопрос оценки качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "\n",
    "По данной выборке $X = (x_1, x_2, \\ldots, x_n)$ и заданному заранее числу кластеров $k$ алгоритм $KMeans$ строит набор кластеров $S = \\{S_1, S_2, \\ldots, S_k\\}$ так, чтобы набор $S$ минимизировал функцию:\n",
    "$$\n",
    "\\sum_{i=1}^{k}{\\sum_{x \\in S_i}{||x-\\mu_i||^2}}\n",
    "$$\n",
    "Где $\\mu_i$ - это центроид кластера $S_i$.\n",
    "\n",
    "Алгоритм:\n",
    "1. Инициализировать $\\mu_i$ -- центроиды кластеров\n",
    "2. Каждому $x_i$ выдать номер кластера (по диаграмме Воронова, т.е. выбираем кластер, ближайший по евклидовому расстоянию)\n",
    "3. Пересчитать центроиды $\\mu_i$\n",
    "4. Повторить с шага 2 пока изменения не станут незначительными\n",
    "\n",
    "Алгоритм сходится при использовании евклидова расстояния. Иначе, вообще говоря, нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanShift\n",
    "\n",
    "Тут: (http://robot-develop.org/wp-content/uploads/2012/03/seg3.pdf)\n",
    "\n",
    "Не нужно задавать число кластеров (у метода нет параметров).\n",
    "Выбирается ядро $K(x)$ и по исходной выборке мы строим функцию плотности вероятности (ядерное сглаживание).\n",
    "\n",
    "Вычисление градиента $f(x)$ - ядерного сглаживания даёт выражение для mean shift и всё такое.\n",
    "Идея в том, чтобы входные точки для кластеризации, смещать в сторону ближайшей моды ядерно сглаженной плотности вероятности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity Propagation\n",
    "\n",
    "http://ijcai.org/Proceedings/11/Papers/373.pdf\n",
    "\n",
    "Заводим таблицы:  similarity[i, j], responsibility[i, j] и availability[i, j] и обновляем последние две итеративно, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение с подкреплением. Оптимизация state-value function. Q-function, policy. Стратегии блуждания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Книга по RL](https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Основные понятия: ошбики in out, функция роста, точка поломки, размерность Вапника-Червоненкиса, bias, variance, валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначения:\n",
    "* $f: \\mathcal{X} \\rightarrow \\mathcal{Y}$ - неизвестная целевая функция\n",
    "* $\\mathcal{D} = \\{ (x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N) \\}$ - датасет, набор данных для обучения (тут $x_i$ - это вектор признаков, а $y_i$ - ответ)\n",
    "* $\\mathcal{A}$ - алгоритм обучения\n",
    "* $\\mathcal{H}$ - множество гипотиз, из которых будет выбрана финальная гипотеза (выбор производится алгоритмом обучения $\\mathcal{A}$\n",
    "* $g$ - финальная гипотеза, которая претендует на $g(x) \\approx f(x)$\n",
    "* $h$ - конкретная гипотеза из $\\mathcal{H}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем для простоты рассматирвать задачу классификации, где классы - это $1$ или $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введём понятие in и out error (**внешних и внутренних ошибок** для конкретной гипотезы $h$):\n",
    "\n",
    "* $E_{in}(h) = \\frac{1}{N}\\sum_{n=1}^{N}{e(h(x_n), f(x_n))}$\n",
    "* $E_{out}(h) = \\mathbb{E}_{x}{[e(h(x), f(x))]}$\n",
    "\n",
    "Тут $e(h(x), f(x))$ - это мера ошибки, например она может быть бинарной (1 если $h(x) \\neq f(x)$ и 0 иначе) или квадратичной, т.е. квадрат разницы $h(x)$ и $f(x)$.\n",
    "\n",
    "Заметим, что гипотеза $h$ закрепляется до момента получения датасета. В таком случае, для закреплённой заранее гипотезы, выполняется **неравенство Хёфдинга**:\n",
    "$$\n",
    "    \\mathbb{P}[|E_{in}(h)-E_{out}(h)| > \\epsilon] \\leq 2e^{-2\\epsilon^2N}\n",
    "$$\n",
    "Что нам даёт некоторые гарантии на то, как сильно, на генеральной совокупности, выбранная модель (гипотеза) будет лажать.\n",
    "Но закреплять гипотезу до получения датасета и дальше её использовать - это затея нерациональная. Нам бы хотелось выбирать финальную гипотезу $g$ из всего множества $\\mathcal{H}$ после получения датасета. И нам бы хотелось надеяться, что вероятность $\\mathbb{P}[|E_{in}(g)-E_{out}(g)| > \\epsilon]$ - это что-то маленькое.\n",
    "\n",
    "Мы не можем написать для выражения вероятности для $g$ то же неравенство Хёфдинга, ибо $g$ выбирается исходя из $\\mathcal{D}$, но можно заметить, что собычтие $|E_{in}(g)-E_{out}(g)| > \\epsilon$ тянет за собой то, что хоть одно из событий $|E_{in}(h)-E_{out}(h)| > \\epsilon$ случится ($h \\in \\mathcal{H}$), откуда сложением вероятностей получаем ещё одно неравенство:\n",
    "$$\n",
    "    \\mathbb{P}[|E_{in}(g)-E_{out}(g)| > \\epsilon] \\leq 2Me^{-2\\epsilon^2N}\n",
    "$$\n",
    "Где $M$ - число гипотех в $\\mathcal{H}$. Если гипотез очень много или бесконечно много, то грусть.\n",
    "Можно переписать это выражение на вероятность так: из неравенства следует, что с вероятностью как минимум $1 - 2Me^{-2N\\epsilon^2}$ верно $|E_{out} - E_{in}| \\leq \\epsilon$, т.е. $E_{out} \\leq E_{in} + \\epsilon$. Далее, вводя желаемую вероятность $\\delta = 2Me^{-2N\\epsilon^2}$ можно вывести выражение для $\\epsilon$ через $\\delta$ и:\n",
    "$$\n",
    "    E_{out}(g) \\leq E_{in}(g) + \\sqrt{\\frac{1}{2N}\\ln{\\frac{2M}{\\delta}}}\n",
    "$$\n",
    "**Суть**: это ограничение сверху на $E_{out}(g)$ было получено исходя из того, что мы брали сумму вероятностей по всем событиям $|E_{in}(h)-E_{out}(h)| > \\epsilon$. Мы никак не учитывали то, что наступление этих событий может перекрываться, т.е. в $\\mathcal{H}$ могут быть близкие гипотезы, которые выдают одни и те же значения ошибок, а значит и событие такое для них наступит одновременно. На деле они сильно перекрываются, что намекает на поиски более хорошего ограничения сверху на $E_{out}(g)$. Тут на помощь к нам идёт Вапник и Червоненкис.\n",
    "\n",
    "Тут начинается комбинаторщина. Пара определений:\n",
    "* **Дихотомия** - это вектор из 0 и 1 (или -1 и 1). Соответственно **множество дихотомий**, генерируемых набором гипотиз $\\mathcal{H}$ - это такое вот множество $\\mathcal{H}(x_1, \\ldots, x_N) = \\{ (h(x_1), \\ldots, h(x_N)) | h \\in \\mathcal{H} \\}$. \n",
    "* **Функция роста** (growth function) - это функция $m_{\\mathcal{H}}(N) = \\max_{\\mathcal{X}}{|\\mathcal{H}(x_1, \\ldots, x_n)|}$, т.е. она числу $N$ сопоставляет максимально возможное число дихотомий, которое набор гипотих $\\mathcal{H}$ может породить на датасете размера $N$ (максимум среди всех возможных датасетов)\n",
    "\n",
    "Очевидно: $m_{\\mathcal{H}}{(N)} \\leq 2^N$\n",
    "\n",
    "* **Точка поломки** (для $\\mathcal{H}$) - это такой размер $k$ датасета, что $m_{\\mathcal{H}}(k) < 2^N$, т.е. множество гипотез уже не всесильно и разделить любыми способами не может.\n",
    "\n",
    "Можно вывести для разных наборов гипотиз точки поломки и вообще значения функции роста:\n",
    "* Перцептрон на $d$ мерном пространстве: может всё до момента поломки равного $d + 2$. (Для плоского случая 4 точки уже не разделишь, а 3 ещё можно (тут важно, что функция роста максимизирует по возможным датасетам, ибо 3 точки на одной линии перцептрон всеми способами тоже не может разделить)).\n",
    "* Простые случаи: луч, отрезок на прямой (сам считай или иди в книгу Learning From Data)\n",
    "* Полигональные гипотезы (всё, что внутри полигона - 1, остальное - 0). Нужно расположить точки датасета по кругу и заметить, что полигонами с вершинами в точках датасета можно разделить всеми способами, а значит точка поломки такого набора гипотез БЕСКОНЕЧНА и функция роста всегда равна $2^N$.\n",
    "\n",
    "* **Размерность Вапника-Червоненкиса** - $d_{vc}$ - это наибольшее такое $k$, что $m_{\\mathcal{H}}{(k)} = 2^k$, т.е. $d_{vc}$ на 1 меньше точки поломки.\n",
    "\n",
    "Без доказательства сейчас будет, но это всё позволяет нам построить следующую оценку: Для любого уровня $\\delta > 0$\n",
    "$$\n",
    "    E_{out}(g) \\leq E_{in}(g) + \\sqrt{\\frac{8}{N}\\ln{\\frac{4m_{\\mathcal{H}}{(2N)}}{\\delta}}} \\leq \n",
    "                    E_{in}(g) + \\sqrt{\\frac{8}{N}\\ln{\\frac{4((2N)^{d_{vc}} + 1)}{\\delta}}}\n",
    "$$\n",
    "верно с вероятностью $\\geq 1 - \\delta$\n",
    "\n",
    "Почему это более ок оценка? Потому, что пока $d_{vc}$ - не бесконечно, то $m_{\\mathcal{H}}{(N)}$ ограничена сверху полиномом. Чем сложнее модель (т.е. больше $d_{vc}$, тем хуже *генерализуемость*.\n",
    "\n",
    "Отсюда можно выносить всякие умазаключения про подходящий размер выборки для *генерализации* применяемого метода.\n",
    "\n",
    "При выборе модели обучения, т.е. множества гипотез $\\mathcal{H}$ мы должны постараться найти золотую середину: \n",
    "* Если модель слишком сложна, т.е. размерность ВЧ большая, то мы получаем большой штраф за сложность модели, но при это имеем возможность лучше приблизить имеющийся датасет, т.е. уменьшить $E_{in}$\n",
    "* Иначе, мы уменьшаем штраф, а значит получаем более хорошую генерализуемость (т.е. $E_{in}$ приближается к $E_{out}$), но тогда страдает сам $E_{in}$.\n",
    "\n",
    "NB: весь \"анализ\" выше относился к бинарным функциям $h$ и $f$, но на деле пофиг, можно чёто подаказывать и для real-valued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вещественных функций гипотез и цели можно исопльзовать анализ **bias-variance**. Раскрывая следующее выражение:\n",
    "$$\n",
    "    \\mathbb{E}_{\\mathcal{D}}[E_{out}(g^{(\\mathcal{D})})] = \\mathbb{E}_x[\\mathbb{E}_{\\mathcal{D}}[(g^{(\\mathcal{D})}(x)-\\overline{g}(x))^2] + (\\overline{g}(x)-f(x))^2]\n",
    "$$\n",
    "Вот:\n",
    "* $\\mathbb{E}_{\\mathcal{D}}[(g^{(\\mathcal{D})}(x)-\\overline{g}(x))^2]$ - это variance\n",
    "* $(\\overline{g}(x)-f(x))^2$ - а это bias\n",
    "\n",
    "Суть:\n",
    "* Если мы возьмём маленькую модель, например такую, что множество всех гипотез ограничено одной гипотезой, то ясно, что variance такой модели будет нулевой, а вот $bias$ будет большим, скорее всего, т.к. у нас модель ваще не смотрит на датасет.\n",
    "* Если же модель будет сложной, то между гипотезами и разница будет большая, а значит variance растёт, а вот bias падает, т.к. мы средняя гипотеза должна как-то приближаться к целевой функции...\n",
    "\n",
    "С кросс-валидацией и валидацией вроде более или менее всё ясно (с мат. точки зрения), а вот регуляризацию нужно подробнее изу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
